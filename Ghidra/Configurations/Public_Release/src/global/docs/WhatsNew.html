<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<HTML>
  <HEAD>
    <TITLE> Ghidra What's New</TITLE>
	<STYLE type="text/css" name="text/css">
		li { font-family:times new roman; font-size:14pt; font-family:times new roman; font-size:14pt; margin-bottom: 8px; }
		h1 { color:#000080; font-family:times new roman; font-size:28pt; font-style:italic; font-weight:bold; text-align:center; color:#000080; font-family:times new roman; }
		h2 { padding-top:20px; color:#984c4c; font-family:times new roman; color:#984c4c; font-family:times new roman; font-size:18pt; font-weight:bold; }
		h3 { margin-left:40px; padding-top:10px; font-family:times new roman; font-family:times new roman; font-size:14pt; font-weight:bold; }
		p { margin-left:40px; font-family:times new roman; font-size:14pt; }
		table, th, td { border: 1px solid black; border-collapse: collapse; font-size:10pt; }
		td { font-family:times new roman; font-size:14pt; padding-left:10px; padding-right:10px; text-align:left; vertical-align:top; }
		th { font-family:times new roman; font-size:14pt; font-weight:bold; padding-left:10px; padding-right:10px; text-align:left; }
		code { color:black; font-family:courier new; font-size: 12pt; }
		span.code { font-family:courier new font-size: 14pt; color:#000000; }
	 </STYLE>
  </HEAD>

  <BODY>

	<H1>Ghidra: NSA Reverse Engineering Software</H2>
    
    <P>
    Ghidra is a software reverse engineering (SRE) framework developed by NSA's Research Directorate.
    This framework includes a suite of full-featured, high-end software analysis tools that enable
    users to analyze compiled code on a variety of platforms including Windows, MacOS, and Linux.
    Capabilities include disassembly, assembly, decompilation, graphing, and scripting, along with
    hundreds of other features.  Ghidra supports a wide variety of processor instruction sets and 
    executable formats and can be run in both user-interactive and automated modes.  Users may also
    develop their own Ghidra plug-in components and/or scripts using the exposed API.  In addition there are
    numerous ways to extend Ghidra such as new processors, loaders/exporters, automated analyzers,
    and new visualizations.
    </P>
    
    <P>
    In support of NSA's Cybersecurity mission, Ghidra was built to solve scaling and teaming problems
    on complex SRE efforts, and to provide a customizable and extensible SRE research platform.  NSA
    has applied Ghidra SRE capabilities to a variety of problems that involve analyzing malicious
    code and generating deep insights for NSA analysts who seek a better understanding of potential
    vulnerabilities in networks and systems.
    </P>
    

    <H1> What's new in Ghidra 10.0 beta</H1>

	<H2>Ghidra 10.0 Final Release<H2>
	
	<P>We anticipate pushing out the final Ghidra 10.0 release sometime towards mid to end of June 2021.  We appreciate any feedback you can provide, especially in any
	new feature areas such as the debugger, and thanks for all your contributions and feedback you've already given!<P>
	
    <H2>Debugger</H2>
    
    <P>With the release of Ghidra 10.0-BETA, we are excited to officially introduce our new Debugger. It is still geared primarily for user-mode application debugging on Linux and Windows;
    however, you may find its components usable in other scenarios. To get started, please Ghidra Functionality / Debugger / Getting Started in the Help. For most, it is as easy as importing
    your program, opening it with the Debugger tool, and clicking the "bug" icon in the main toolbar. The Debugger's features include:</P>
    <BLOCKQUOTE><UL>
    
    <li>Debugging user-mode Windows applications on x64 hosts via dbgeng.dll/WinDbg (including 32-bit x86 applications via WoW64)</li>
    <li>Debugging user-mode Linux applications on amd64/x86_64 hosts via GDB (including 32-bit i686/x86 applications)</li>
    <li>Quick launch to locally debug the current program</li>
    <li>Recording of observations from a live debug session into a Ghidra Trace database</li>
       <BLOCKQUOTE><UL>
       <li>NOTE: We do <em>not</em> currently plan to support Trace database upgrades in future releases</li>
       </UL></BLOCKQUOTE>

    <li>Sharing of Trace databases via a Ghidra server</li>
    <li>Time-travel(-like) exploration and annotation of Trace databases.</li>
       <BLOCKQUOTE><UL>
       <li>Includes capture of memory and register values over time</li>
       <li>Utilizes p-code emulation to interpolate and extrapolate ahead of the target</li>
       </UL></BLOCKQUOTE>
    <li>Export a Trace's memory / listing (at a given time) to ASCII, Binary, HTML, Intel Hex, and XML</li>
    </UL></BLOCKQUOTE>
    <H3>New Views:</H3>
        <BLOCKQUOTE><UL>
        <li>Targets list for managing platform debugger connections</li>
        <li>Interpreter Panel for accessing the platform debugger's command-line interface</li>
        <li>Console Panel for viewing log messages and resolving problems</li>
        <li>Objects Tree for accessing and commanding the platform debugger via a graphical user interface
        <BLOCKQUOTE>
            Includes Resume, Interrupt, Step, Launch, etc.
        </BLOCKQUOTE>
        <li>Dynamic Listing for viewing and annotating memory in a Trace</li>
        <li>Breakpoint management:</li>
            <BLOCKQUOTE>
                <li>Breakpoints viewer showing breakpoints from all live sessions, as well as breakpoints bookmarked in Program databases</li>
                <li>Dynamic Listing actions permitting placement, toggling, and removal of breakpoints at the current address</li>
                <li>(Static) Listing actions permitting the bookmarking, placement, toggling, and removal of breakpoints</li>
            </BLOCKQUOTE>
        <li>Registers Table for viewing and annotating values in a Trace and/or modifying values of the target</li>
        <li>Watches Table for evaluating SLEIGH expressions on the Trace or target machine state</li>
            <BLOCKQUOTE>
            NOTE: Dependent registers and memory are captured to the Trace, if recording from a live target
            </BLOCKQUOTE>
        <li>Stack / Frame Table for navigating frame contexts</li>
        <li>Threads Timeline for listing threads and for navigating thread and time contexts</li>
        <li>Modules Table for viewing modules and sections, and for mapping live Trace addresses to static Program database addresses</li>
        <li>P-code Stepper/Emulator for debugging SLEIGH language specifications in-situ</li>
        <li>Memory/Time plotter for viewing trace events</li>
        </UL></BLOCKQUOTE>
    <H3>New APIs:</H3>
        <BLOCKQUOTE><UL>
        <li>Trace database (backs our time-travel features and populates our machine-state UIs)</li>
        <li>Platform debugger model (our abstraction of platform debuggers into a reflexive API)</li>
        <li>Abstract SLEIGH / p-code execution (backs our emulation, trace interpolation, and SLEIGH watches)</li>
        </UL></BLOCKQUOTE>
    <H3>Nascent support for the following:</H3>
        <BLOCKQUOTE><UL>
        <li>Other modes, including kernel-mode, and remote debugging, as supported by the platform debugger.</li>
            <BLOCKQUOTE>
            WARNING: Ghidra's Trace recorder may not know how to cope with the environment and objects presented, causing it to behave poorly, e.g., it may greedily record things,
             exhaust resources, crash Ghidra, crash your debugger, crash your target, etc.
            </BLOCKQUOTE>
        <li>Connection to WinDbg Preview (via dbgmodel.dll) on Windows</li>
        <li>Connection to a JVM or DalvikVM via JDI (JDWP)</li>
        <li>Support for tracing the following architectures via GDB: arm, m68k, mips, powerpc (depending on versions and variants)</li>
        <li>Support for tracing the following architectures via JDI: Java, Dalvik (depending on versions and variants)</li>
        </UL></BLOCKQUOTE>
    <H3>Support in progress for the following:</H3>
        <BLOCKQUOTE><UL>
        <li>Pure program emulation, i.e., simulating a trace from a program, without an actual target</li>
        <li>Connection to LLDB for macOS and iOS targets. This will likely support other targets and platforms, too.</li>
        </UL></BLOCKQUOTE>
    <H3>Known Issues:</H3>
        <BLOCKQUOTE>
        <P>
        While the debugger is quite usable, as this is its initial release, it is not as mature as the other features of Ghidra.
        The following are areas where we've seen the most recurring problem tickets, for which we've not been able to produce quick fixes.
        We don't necessarily have answers for these problems, so we're listing them here so people are aware, and to open up some discussion.
        </P>
        
        <H4>1. The breakpoints interface is complicated</H4>
        <P>
        We attempt to present an abstract view of breakpoints and save them to the program databases, but we also didn't want to hide the raw breakpoint locations listed for each target.
        This is the basis of our "logical breakpoint" concept, but it has introduced some complexity and confusion, which is obviously not what we intended.
        One common misconception is that placing a breakpoint in the program image then launching the program should cause an initial break at that spot.
        This is a totally reasonable expectation, but one which cannot necessarily be implemented, depending on the capabilities of the connected debugger.
        Typically, the user must launch the target, take the initial break provided by the debugger, then place the desired breakpoints.
        While we've made some changes recently to try to communicate actual breakpoint state, it has not alleviated this confusion.
        We're also not sure if this is just a learning curve thing, or a real problem regarding UI intuition.
        </P>
        
        <H4>2. Loading the correct dbgeng DLL for Windows debugging is a kludge</H4>
        <P>
        It turns out the OpenJDK 11 JVM is already linked to <code>dbgeng.dll</code> in order to implement its service agent.
        This created two potential issues:
        </P>
        <BLOCKQUOTE><OL>
          <li>It's difficult/impossible to link an alternative DLL. It always gets <code>C:\windows\system32\dbgeng.dll</code>.</li>
          <li>The JVM's debugging session and Ghidra's debugging session could potentially conflict.</li>
        </OL></BLOCKQUOTE>
        <P>
        While we figured that out some time ago, we worked around it by copying the desired DLL(s) into the JRE running Ghidra.
        This moved things along nicely, allowing us to postpone a better solution, while coding up the connector.
        Furthermore, issue (2) did not seem to be a problem, presumably because we never tried triggering the issue.
        Regarding issue (1), we could (or so we thought) ignore it, since the system copy had the required features.
        It was almost the same as WinDbg's, but with some disabled bits, e.g., the <code>.server</code> command.
        However, it seems there are more nuances than that.
        Ideally, we'd find an environment variable to override the JVM's link to <code>dbgeng.dll</code>, so that we can link to a configured WinDbg installation.
        Furthermore, we have some configuration management to do in cataloging and deciding which versions of WinDbg to prescribe.
        </P>
        
        <H4>3. Errors due to configuration / installation issues are not clear</H4>
        <P>
        While we've done our best to document version requirements, when those requirements are not met, we don't fail fast.
        This typically leads to cryptic error messages.
        We neglected such checks in part, because we weren't sure what the requirements were until we had tested, and partly because we didn't want to limit the user.
        We now find ourselves in the pickle of needing to go back and code in some reasonable checks, while perhaps allowing for optional bypasses.
        That would allow for issues from configuration to be more quickly diagnosed.
        </P>
        <P>
        However, there's also the case of unexpected user configurations even within the prescribed versions.
        For example, connecting GDB to a remote or system stub may prevent <code>proc info mappings</code> or <code>maint info sections</code> from returning anything useful, and we rely on them for the memory and module maps.
        Granted, some of these situations are outside the prescribed use cases, not all are.
        While this can be addressed in support forums or FAQs, we really ought to put in some better diagnostics.
        </P>
        
        <H4>4. A trace database is required to accomplish even basic operations, and it's becoming a burden.</H4>
        <P>
        The trace database was a bit serendipitous.
        We originally connected machine-state UI components directly to the debugging interfaces, but this created some problems:
        </P>
        <BLOCKQUOTE><OL>
        <li>If a request was never answered on a blocking call, we risked hanging the UI.</li>
        <li>Our caches (used to reduce queries  to the debugger connection) grew in size.</li>
        </OL></BLOCKQUOTE>
        <P>
        While converting the debugging API to asynchronous queries helped us avoid a good portion of UI hangs, we still needed something to mediate between the UI's synchronous calls and the debugging API's asynchronous calls.
        This was accomplished by introducing a database.
        This allowed us to answer synchronous callbacks from the UI immediately, and later emit update once aysnchronous debugger API requests were completed.
        Additionally, because the database is stored on disk, using in place of some in-memory caches alleviated memory requirements.
        Our first attempt used an extension of a standard ProgramDB, but that proved insufficient.
        Thus, we needed a new kind of database for storing target machine state.
        We thought this an opportunity to build something new, and aware of other research efforts in "time-travel" or "timeless" debugging, we introduced a "trace database."
        </P>
        <P>
        Currently, a trace database (even if just an ephemeral one) is required for the UI to interact with a target's machine state.
        While we anticipated some risk, we were perhaps a little too excited about traces to give it proper credence.
        There are a good bit of dependencies and resource needs to get a trace going.
        Notably, the system must know the target architecture, and usually also its ABI.
        Additionally, all combined &mdash; the debugging API, the GADP server and client, the trace database, and the UI &mdash; there's still plenty of unchecked in-memory caching going on, risking resource exhaustion.
        Regarding target architecture recognition: if it's not on the (currently small) list, the target cannot be traced, and so its state cannot be viewed.
        This precludes the user from viewing the target's memory in the UI, even if disassembly is not desired.
        Furthermore, a table of register names and values could easily be presented without first recognizing the architecture.
        The latter is mitigated somewhat by the "Objects" viewer's table mode, using the Registers container as the root, but this is not an intuitive solution until the user is familiar with that viewer.
        We need either/both to support simpler forms of tracing that have fewer dependencies and/or to implement some state viewers outside of tracing &mdash; but without taking us back to our original problems.
        </P>
        
        <H4>5. The threads timeline view has not been receiving enough TLC</H4>
        <P>
        This particular view was meant to expose the time axis of the trace database in a sort of "cool" fashion by plotting the lifetimes of every observed thread.
        Some work was put in to get that plot working, but it has been the source of some pernicious bugs that are simply no fun to work on.
        One of the more annoying ones deals with caret placement, which is essentially the "scroll bar" for time.
        It seems the range of that widget does not always match the range of the timeline plot, causing confusion surrounding a critical parameter in navigating the trace: time.
        It would seem an easy issue to fix, except that we're no longer sure a single caret is really the best way to navigate time.
        We're honestly looking at dropping that timeline pane altogether and just accomplishing the same plot using a custom cell editor on the threads table.
        However, the only other means we have of navigating time is the "Time" table, which generally just lists events.
        We'd like to devise something more cogent, perhaps allowing queries or establishing visual cues to identify interesting points in time.
        </P>
        </BLOCKQUOTE>
	<BR />
        
    <H2>User-defined Compiler Specification Extensions</H2>
    
        <P>Ghidra 10.0 adds support for user-defined extensions to the <b>compiler specification</b> assigned to a specific Program.  In particular,
            users can now define their own:</P>
        <BLOCKQUOTE><UL>
            <LI><B>Calling Conventions</B> - which inform analysis and decompilation how parameters are passed between functions,</LI>
            <LI><B>Call-Fixups</B> - which substitute behavior for specific CALLs when analyzing a function that makes them, and</LI>
            <LI><B>Callother-Fixups</B> - which substitute behavior for certain Instructions when analyzing a function that contains them.</LI>
        </UL></BLOCKQUOTE>

    <P>Prior releases only provided compiler specifications statically via <B>.cspec</B> files in the distribution.  The new extensions
      are stored as part of the Program and can be added or adjusted dynamically as users build up their understanding.
      Extensions can be added from the <B>Specification Extensions</B> tab under the <I>Options</I> dialog for the Program.</P>

    <BR />
    
    <H2>Prototype Class Recovery From RTTI</H2>
    <P>A new prototype script <B>RecoverClassesFromRTTIScript</B> which recovers class information using RTTI structures has been added. 
    The script recovers class hierarchy, inheritance types, constructors and destructors, class data types, and more. If available, PDB information 
    is used to help fill in class structures with known names and types for class member data. If PDB is unavailable, the decompiler structure 
    recovery is utilized to populate class data structure members.</P>
    <BLOCKQUOTE><UL>
        <P> NOTE: As this is a prototype script, the location, names, layout of data types, and default virtual function names created by this script are
        likely to change in the future once an official design for Object Oriented representation is determined.<P>
        <P>NOTE: Windows class recovery is fairly complete and tested, however GCC class recovery is still in early development.</P>
        <P>NOTE: For best results, run this script on freshly imported and analyzed programs. No testing has been done on programs previously imported with pre-existing user mark-up.</P>
    </UL></BLOCKQUOTE>
    <P>Two related scripts have been added, ApplyClassFunctionSignatureUpdatesScript and ApplyClassFunctionDefinitionUpdatesScript, which are fix-up scripts that can be applied if a user 
    makes changes to a virtual function recovered by the RecoverClassesFromRTTIScript. Both scripts identify differences between Function Signatures in the 
    Listing and Function Definitions in the Data Type Manager, but the first script fixes all changes to match the signature and the second to match the definition. NOTE: These
    scripts are a temporary measure until an underlying connection between function signatures and their associated function definition can be implemented in the Ghidra API.</P>
    <BR />

    <H2>PDB Symbol Server</H2
    <P>Managing and applying PDB files has a much improved GUI, including support for multiple symbol server locations.</P>
    
    <BR />

    <H2>Saved Analysis Options Configuration</H2>
    
    <P>Analysis options configurations can be saved by name and quickly changed using a new feature in the Analysis configuration menu. The
    last used named configuration will be used as the default option the next time a program is analyzed even after exiting Ghidra.  This can be useful
    to disable one or more options, such as Stack Analysis, if the analyzer is providing poor results or the analysis is not desired for a type of binary
    you will be working with.  For example some analysis options should be turned off by default for all suspect malware binaries on the first pass to avoid
    issues with some types of obfuscation.<P>
    
    <H2>Graphs</H2>
    
    <P>Data types can get complicated and might have many references to other data structures, either by declaring them as a field or as a pointer at another data type.
    A general graph of data type relationships from the Data Type manager has been added. In addition defined data structures in memory can be graphed by following all references
    to other defined data or code using the Graph->Data menu.<P>
    
    <P>A new favored edge and associated layout has been added for hierarchical graphs.  This edge can help closely align graph nodes that should
    be arranged more closely to a neighboring node, for example the node from a fall-thru edge should be arranged closer than from a branching edge.<P>
    
    <BR />     
    
    <H2>Structure/Union Changes</H2>
    
    <P>A significant refactor of the Composite datatype interfaces and internals has been completed which affects
    Structures and Unions.  The changes are intended to provide a more understandable API and allow an alignment 
    to be specified for non-packed composites (aka, composites with internal alignment disabled).</P>
    
    <H3>Editor Changes</H3>
    
    <P>Previously, the editor contained an <B>Align</B> checkbox which determined if packing should be performed or not.
    This checkbox has been replaced by a checkbox adjacent to the <B>pack</B> choices (i.e., enable/disable packing).  
    Generally, this setting would be "not-checked" (i.e., disabled) when reverse-engineering the content of a 
    structure so that components may be placed at specific offsets.  Only when there is a complete understanding 
    of all components, as conveyed by a source header file, should
    this be enabled with the appropriate <B>pack</B> and <B>align</B> settings specified.  In addition, when <B>pack</B>
    is enabled it is important that the component datatypes emit the correct alignment to ensure proper 
    placement during packing.</P> 
    
    <P>The <B>align</B> setting may know be used when packing is disabled with the composite adopting 
    the specified alignment.  The default alignment for a non-packed composite is <B>1</B> which is consistent 
    with the current behavior in Ghidra 9.x.</P>
     
    <H3>Composite API Changes</H3>
    
    <P>The various pack and align methods of the <I>Composite</I> (i.e., <I>Structure</I> and <I>Union</I>) 
    API have been changed extensively. Since these changes were primarily intended to "cleanup" the
    interface we decided to eliminate (i.e., not deprecate) the old methods.  It was felt leaving them in
    place would only confuse matters when attempting to understand the new interface.  It is also believed that 
    most uses of the API generally do not utilize the pack and align settings which should minimize the 
    impact to existing user code.<P>
    
    <P>The tables below convey the <I>Composite</I> API changes as they relate to the pack and align settings.</P>
    <BLOCKQUOTE>
    <P>
    <TABLE WIDTH="100%">
       <TR>
           <TD COLSPAN="3" padding-top:14px; padding-bottom:14px;><CENTER><B>Composite Pack API Changes</B></CENTER></TD>
       </TR><TR style="background-color:#DFDFDF;">
           <TH>Old Method 9.x</TH><TH>New Method 10.0</TH><TH>Comments</TH>
       </TR><TR>
           <TD><CODE>setInternallyAligned(<font color="blue">boolean</font>)</CODE></TD>
           <TD><CODE>setPackingEnabled(<font color="blue">boolean</font>)</CODE></TD>
           <TD> </TD>
       </TR><TR>
           <TD><CODE>isInternallyAligned()</CODE></TD>
           <TD><CODE>isPackingEnabled()</CODE></TD>
           <TD>Equivalent to: <CODE>getPackingType() != DISABLED</CODE></TD>
       </TR><TR>
           <TD><CODE>setPackingValue(NOT_PACKING)<BR>setPackingValue(1..n)</CODE></TD>
           <TD><CODE>setToDefaultPacking()<BR>setExplicitPackingValue(1..n)<BR>pack(1..n)</CODE></TD>
           <TD>Packing will be enabled if not previously enabled.  Old constant <CODE>NOT_PACKING</CODE> has been elliminated.</TD>
       </TR><TR>
           <TD><CODE>getPackingValue()</CODE></TD>
           <TD><CODE>getExplicitPackingValue()</CODE></TD>
           <TD>New method use does not directly map (see Javadocs).  Old constant <CODE>NOT_PACKING</CODE> has been elliminated.</TD>
       </TR><TR>
           <TD> </TD>
           <TD><CODE>hasDefaultPacking()</CODE></TD>
           <TD>Equivalent to: <CODE>getPackingType() == DEFAULT</CODE></TD>
       </TR><TR>
           <TD> </TD>
           <TD><CODE>hasExplicitPackingValue()</TD>
           <TD>Equivalent to: <CODE>getPackingType() == EXPLICIT</CODE></TD>
       </TR><TR>
           <TD> </TD>
           <TD><CODE>getPackingType()</TD>
           <TD>Possible values: <CODE>DISABLED</CODE>, <CODE>DEFAULT</CODE> or <CODE>EXPLICIT</CODE></TD>
       </TR><TR>
           <TD><CODE>realign()</CODE></TD>
           <TD><CODE>repack()</CODE></TD>
           <TD>Update component sizing and placement if composite has packing enabled. 
             Changes to data organization (e.g., type sizes and alignments) are problematic and difficult to fully 
             recover from.  Any attempted repair to component sizes and alignments need to be performed in 
             dependency order (ignoring pointer components).</TD>
       </TR>
    </TABLE>
    <P>
    <TABLE WIDTH="100%">
       <TR>
           <TD COLSPAN="3"><CENTER><B>Composite Align API Changes</B></CENTER><BR>
           <B>NOTE!</B> The old alignment <I>set</I> methods previously forced packing to be enabled.  
             This is no longer the case since the alignment setting is now supported for composites 
             where packing is not enabled.  If packing should be enabled a separate 
             call to a packing enablement method (see above) is required.  When packing is <U>disabled</U>
             the composite's computed alignment will match the specified align setting (default is 
             1 which is consistent with old behavior).
           </TD>
       </TR><TR style="background-color:#DFDFDF;">
           <TH>Old Method 9.x</TH><TH>New Method 10.0</TH><TH>Comments</TH>    
       </TR><TR>
           <TD><CODE>setToDefaultAlignment()</CODE></TD>
           <TD><CODE>setToDefaultAligned()</CODE></TD>
           <TD>Default alignment for a non-packed composite is 1.  When packing is enabled the 
           default alignment is a function of the component packing.</TD>
       </TR><TR>
           <TD><CODE>isDefaultAligned()</CODE></TD>
           <TD><CODE>isDefaultAligned()</CODE></TD>
           <TD>Equivalent to: <CODE>getAlignmentType() == DEFAULT</CODE></TD>
       </TR><TR>
           <TD><CODE>setToMachineAlignment()</CODE></TD>
           <TD><CODE>setToMachineAligned()</CODE></TD>
           <TD>Non-packed composites will have an alignment which equals the machine alignment
           specified by the compiler specification (data organization).  Packed structures 
           will have an alignment which is a multiple of the machine alignment.</TD>
       </TR><TR>
           <TD><CODE>isMachineAligned()</CODE></TD>
           <TD><CODE>isMachineAligned()</CODE></TD>
           <TD>Equivalent to: <CODE>getAlignmentType() == MACHINE</CODE></TD>
       </TR><TR>
           <TD><CODE>setMinimumAlignment(DEFAULT_ALIGNMENT_VALUE)<BR>setMinimumAlignment(1..n)</CODE></TD>
           <TD><CODE>setToDefaultAligned()<BR>setExplicitMinimumAlignment(1..n)<BR>align(1..n)</CODE></TD>
           <TD> 
             If an explicit minimum alignment is set (1..n), non-packed composites will have an alignment 
             which equals this value, while packed structures 
             will have an alignment which is a multiple of this value.
             Old constant <CODE>DEFAULT_ALIGNMENT_VALUE</CODE> has been eliminated.
           </TD>
       </TR><TR>
           <TD><CODE>getMinimumAlignment()</CODE></TD>
           <TD><CODE>getExplicitMinimumAlignment()</CODE></TD>
           <TD>New method use does not directly map (see Javadocs).  Old constant <CODE>DEFAULT_ALIGNMENT_VALUE</CODE> has been elliminated.</TD>
       </TR><TR>
           <TD></TD>
           <TD><CODE>hasExplicitMinimumAlignment()</CODE></TD>
           <TD>Equivalent to: <CODE>getAlignmentType() == EXPLICIT</CODE></TD>
       </TR><TR>
           <TD></TD>
           <TD><CODE>getAlignmentType()</CODE></TD>
           <TD>Possible values: <CODE>DEFAULT, MACHINE or EXPLICIT</CODE></TD>
       </TR>
    </TABLE>
    </BLOCKQUOTE>
    </P>
    
    <H2>Gradle</H2>
    <P>The build infrastructure has been upgraded to support both Gradle 6 and 7. Gradle 5 is no longer supported.<P>

    <H2>New Processors</H2>
    <P>We are working on .NET/CIL that may make it into the final 10.0 release, but most likely into 10.1</P>

    <H2>Binary Exporter</H2>    
    <P>New exporters that write programs imported with the PE and ELF loaders back to their original file layout have been added.
    Any file-backed bytes that were modified by the user in the program database will be reflected in the written file.
    Bytes that are part of the import process such as relocations or modified Memory Maps are not currently handled.</P>
    
    <H2> 
     <H2>Bug Fixes and Enhancements</H2>
    		<P> Numerous other bug fixes and improvements are fully listed in the <a href="ChangeHistory.html">ChangeHistory</a> file.</P>
    		   
    <BR />
    <H1> What's New in Ghidra 9.2</H1>
        
    <H2> <a id="finePrint92"/>The not-so-fine print: Please Read!</H2>
    
	<P>Ghidra 9.2 is fully backward compatible with project data from previous releases. However, programs opened in 9.2 may no 
	longer be accessible by an earlier Ghidra version if the processor model has been updated.  A processor version
	number mismatch error is displayed if this occurs.  In almost all cases, it is better to use the latest version than to
	attempt to use both Ghidra 9.2 and a previous release, unless absolutely necessary.</P>

	<P>This release includes many new features and capabilities, performance improvements, quite a few bug fixes, and many pull-request
	contributions.  Thanks to all those who have contributed their time, thoughts, and code. The Ghidra user community
	thanks you too!</P>

	<P>NOTE: Ghidra Server: The Ghidra 9.0 server is compatible with Ghidra 9.x clients, however starting with 9.1 the server
	requires clients to use a TLS secure connection for the initial RMI registry port access.  
	If the Ghidra multi-user server is upgraded to 9.2, then all clients must
	upgrade to 9.2.  A 9.x Ghidra client will fall back to a non-TLS connection when accessing the RMI Registry on
	a 9.0 server.  Note that all other server interaction including authentication were and continue to be 
	performed over a secure TLS connection.</P>
	
	<P>Minor Note: FIDB Files: If a processors instruction implementation has changed significantly, any generated .fidb files using that
	processor definition may need to be regenerated.
	Changes that could require regeneration include, change in instruction size, number of operands, the nature of
	the operands, changes in register decoding for an operand.  The x86-64bit has had such changes, for example there were
	changes to the decoded register for many instructions with prefix byte overrides.  All the provided .fidb files have
	been regenerated, and new ones for VS 2017/2019 have been added.</P>
	
	<P>Minor Note: SLA Files: Ghidra-compiled .sla files are not always backwards compatible due to changes in the underlying .sla
	specification.  In the prebuilt Ghidra, all .sla files are rebuilt from scratch.  However if you have local processor modules,
	or are building Ghidra from scratch, you may need to do a clean build.  Any processor modules with changes are normally recompiled
	at Ghidra startup so this situation is rare.</P>
	
	<P>Minor Note: AARCH64 Long: The size of a <b>long</b> on the AARCH64 has been changed from 4-bytes to 8-bytes in the data organization within the
	compiler specification. This change could have ramifications in existing AARCH64 programs using a <b>long</b> within data structures or
	custom storage of function parameters (dynamic storage should not be an issue). An included script <i><b>FixupCompositeDataTypesScript</b></i>
	can be run on programs, only with <i>exclusive checkout</i> in Multi-User, where the datatype sizes for <b>long</b> has changed.  This general script can be used
	whenever a program's base datatypes have changed in the compiler specification, which should be rare occurrence.</P>
	

	<H2>Open Source Based Graphing</H2>
	   <P>Ghidra has been integrated with an open source graph visualization package, called JUNGGRAPHT, to display interactive
	   block graphs, call graphs, AST control flow graphs, as well as a general API to create graphs within plug-ins and scripts.
       Prior to initial public release, graphing had been provided by a legacy graphing package which was unreleasable publicly due to
       licensing issues.</P>
	   
	   <P>Graphs are displayed in a new tabbed graph window. Current location and selection of vertices are kept in sync with other
	   information displays such as the listing and decompiler. Each graph can be filtered and visualized with various
	   layout algorithms to examine the program structure.   In addition, Graphs can be exported in several standard graph formats, such as
	   CSV, GRAPHML, GML, JSON, and VISIO.  The exported file can then be imported into external tools.</P>
	   
	   <P>The graphing capability is implemented by a general service mechanism allowing other graph providers to be implemented
	   to support a favorite graphing tool, however, users will most likely be satisfied with the new default implementation.
	   There will be follow up capabilities such as graph specific popup actions on the the nodes and edges that can be added by
	   the creator of the graph before display. As in everything, the Ghidra team is interested in any feedback you might provide
	   on this new capability.</P>
       
    <H2>JAVA based Universal PDB Reader/Analzyer/Loader</H2>
       <P>Added a new platform-independent PDB Reader/Analyzer/Loader that has the ability to process
       raw PDB files and apply extracted information to a program.  Written in Java, PDBs can be utilized on any supported
       platform, not just on Windows as in prior Ghidra versions. PDBs can be applied during analysis
       or by loading and applying the PDB before analysis.  Information from PDBs can be force-loaded into a program
       with a mismatched PDB signature, which is very useful for extracting datatypes to be used with the
       program from a PDB related to that program.  Loading the PDB utilizes a new underlying Universal
       Reader API.</P>
       <P>The PDB Reader and Analyzer capabilities are an evolutionary development and are expected to be
       expanded in future releases. We expect to improve this feature over time, adding to its capabilities
       and fixing bugs. If the new PDB Analyzer causes issues, you can turn it off and use the original PDB Analyzer.</P>
	   
    <H2>Dynamic Modules: OSGI model for scripting</H2>
       <P>A change to scripting brings a powerful form of dynamic extensibility to Ghidra scripting, where Java source code is (re)compiled, loaded, and
       run without exiting Ghidra. When a script grows large or requires external dependencies, it might be worth the effort to split
       up code into modules.  To support modularity while preserving the dynamic nature of scripts, Ghidra uses OSGi. The new feature
       provides better script change detection, external jar dependencies, script lifecycle management, and modularity.</P>
       <P>To find out more, bring up Help contents in Ghidra, and search for OSGi or Bundles.</P>
	    
    <H2>Decompiler</H2>
    <P>There have been numerous changes to the decompiler addressing quality, readability, and usability. Decompilation has been improved by:
    <ul style="padding-left:80px">
     <li>Fewer Casts - The decompiler can better recognize lower precision operations performed with bigger registers, allowing it to eliminate
    extraneous casts and concatenations.</li>
     <li>Better Strings - All the alternate string formats and encodings recognized by Ghidra are now displayed properly by the decompiler,
    and string references contained inside larger strings are better recognized</li>
    <li>Controllable Namespace Info - Namespace information, as configured by the user, can now be displayed as part of rendering symbols in decompiler output.
    The default minimal display configuration will print only the minimal number of path
    elements necessary to uniquely resolve the symbol within the current scope.</li>
    <li>Arrays - Analysis of array expressions in the decompiler has improved, simplifying many new optimized array access forms.</li>
    </P>
    </ul>
    <P>The decompiler GUI as also been enhanced with the addition of multiple highlights of varying color, called secondary highlights. In addition,
    the Decompiler's Auto Create/Fill Structure commands incorporate datatype information from function prototypes
    and will override undefined or more general datatypes with discovered datatypes that are more specific.</P> 
    <P>There is rewritten more comprehensive Decompiler documentation too!</P>
           	
	<H2>Performance Improvements</H2>
	   <P>There have been major performance improvements in both analysis and the display or filtering of information within GUI components.
	   These changes are most notable on large binaries, with reports of improvements from 24 plus hours to under an hour for analysis.  Some operations
	   were done very inefficiently such that the end user might give up on analysis.  Please report if you notice any severe performance issues
	   or binaries that take a large amount of time to process. If you can find an example binary that is easily obtainable that reproduces
	   the issue, the root cause can be identified and hopefully improved.  There are some continued sore performance areas we are still working
	   such as the non-returning function analyzer.  We hope you will find the binary analysis speed and interactivity much improved.</P>
	   <P>Some specific areas of improvement are binaries with rich datatype information, RTTI information, exception records, large number
	   of bytes, large number of defined symbols, and many symbols at a single address.</P>

    <H2>Function Identification Improvements</H2>
    
        <P>Function Identification databases have been recreated from scratch, including new information for Visual Studio 2017 and 2019 libraries.
        The databases have been cleaned and should overall result in more matches with fewer mis-matched or multiple matches for identified functions.
        In addition the FID libraries had to be rebuilt from scratch due to errors or differences in instruction set decode (especially in the 64-bit X86)
        with prior versions of Ghidra.  The FID is sensitive to the actual instruction bytes, the mnemonic, register, and number of operands.</P>
        
        <P>There are several new improvements that have been identified that will be added in a future release.  Until then to get an even better increased
        positive match rate, turn on the <i>Shared Return Calls Analyzer</i> option <i>Assume Contiguous Functions Only</i>, and possibly <i>Allow Conditional Jumps</i>.
        For normal clean non-heavily optimized, non-malware or obfuscated binaries, these options should cause few issues.</P>
	
	<H2>Symbol Demangling</H2>
	    <P>Both GNU and Microsoft symbol demangling has been greatly improved resulting in fewer unmangled symbols with better function signature recovery.</P>

    <H2>Processor Models</H2>
    	<P>Several new processor specifications have been added, from very old processors to more recent: CP1600, M6809, M8C, RISC-V, V850.</P>
    	<P>Note: the Elan EM78xxx just missed the 9.2 cutoff, but should appear shortly.</P>
    	
    	<P>Many improvements and bug fixes have been made to existing processor
    	specifications: ARM, AARCH64, AVR8, CRC16C, PIC24/30, SH2, SH4, TriCore, X86, XGATE,
    	6502, 68K, 6805, M6809, 8051, and others.  Of note, the AARCH64 has been updated to support all v8.6 spec instructions.
    	Many improvements have been contributed by the Ghidra
    	community, while others were discovered and fixed using a currently internal tool which automates fuzzing
    	of individual instructions against an external emulator or debugger.  We hope to put the tool
    	out in a near term future release.</P>

	<H2>Processor Specification</H2>
	
		<P>Minor changes have been made to the build process of the Sleigh Editor.  For those trying to build it from scratch the
		instructions are a little clearer and should work correctly.  In addition the new POPCOUNT operator is supported.
		For those modifying or studying sleigh processor specifications, who were unaware of the Sleigh Editor, we encourage
		you to give it a try.  We suggest you install/run the Sleigh Editor in a separate Eclipse installation, possibly the Eclipse
		you use with the Ghidra runtime, from the one you are using with the entire Ghidra source code base imported.
		To find out more read the <i>GhidraSleighEditor_README.html</i>.</P>
		
		<P>The External Disassembler is a plug-in useful when developing or trouble-shooting sleigh processor specifications.  It is part of
		the Xtra SleighDevTools project.  The plug-in integrates with an external disassembler such as binutils, and provides a code browser
		field that displays the disassembly from an external disassembler, such as bintutils, at each instruction or undefined byte in the listing.
		The only external disassembler integration provided is binutils, however it is possible to add support for additional external disassemblers.
		Previously the External Disassembler had trouble with instruction sets which have an alternate mode set of instruction
		such as Thumb or MicroMips.  The working aide field has new configuration files to feed different options to the external disassembler
		to choose the correct alternate encoding set.  This also works well with several scripts that also aide in processor development such as
		the <i>CompareSleighExternal</i> script.</P>
		
		<P>A new p-code operation POPCOUNT is supported in sleigh processor specifications. POPCOUNT was mainly added to deal with instructions
		that needed to compute the parity of an operation.
		In addition, the Sleigh compiler error messages have been reworked to be more comprehensible, consistent in format layout, and to provide
		correct line numbers as close to the error as possible.  In addition, several cases have been caught during compilation that previously would
		pass compilation but cause issues during use of the processor.</P>
		    	
    <H2>Dynamic Analysis Framework - Debugger</H2>
        <P>The debugger is very much still in progress. You may have seen some commits, in the Ghidra GitHub master branch, to get in sync with the debugger.
        Stay tuned for more on the Dynamic Analysis Framework soon after the 9.2 release.</P>
    	    	
    <H2>Bug Fixes and Enhancements</H2>
    		<P> Numerous other bug fixes and improvements are fully listed in the <a href="ChangeHistory.html">ChangeHistory</a> file.</P>

    <BR />
    <H1> What's New in Ghidra 9.1</H1>
        
    <H2> <a id="finePrint91"/>The not so fine print: Please Read!</H2>
	
	<P>Minor Note: Ghidra compiled .sla files are not backwards compatible due to the newly added OTHER space for syscalls
	support.  In the prebuilt Ghidra all .sla files are rebuilt from scratch.  However if you have local processor modules,
	or are building Ghidra from scratch, you may need to do a clean build.  You will get an error if an old .sla file is loaded
	without recompilation of the .slaspec file.  Any processor modules with changes are normally recompiled at Ghidra startup
	so this situation is rare.</P>
	
	<H2>Data Improvements</H2>
	
		<P>Bitfields within structures are now supported as a Ghidra datatype.  Bitfield definitions
		can come from PDB, DWARF, parsed header files, and can also be created within the structure
		editor.  All Datatype archives delivered with Ghidra have been reparsed to capture bitfield
		information.  In addition, compiler bitfield allocation schemes have been carefully implemented.
		Full support for bitfield references within the decompiler is planned for a future
		release.</P>
		
		<P>In support of creating bitfields within structures, a new bitfield editor within the
		structure editor has been added.  The Bitfield Editor includes a visual depiction of the
		datatype byte layout and the associated bits.  The BitField Editor simplifies the creation
		of bitfields within a structure.</P>
		
	<H2>System Calls</H2>
		<P>Ghidra now supports overriding indirect calls, CALLOTHER p-code ops, and conditional jumps via new overriding references.
		These references can be used to achieve correct decompilation of syscall-like instructions.  A new script,
		ResolveX86orX64LinuxSyscallsScript, has been provided as part of this initial implementation.
		Future releases will automatically identify and apply system calls for other operating systems and versions.</P>
		
		<P>To support system calls, the decompiler follows references into OTHER address space overlays.
		This allows users to create address spaces on the fly without worrying about conflicts with existing spaces.
		For example, instructions with a unique calling
		convention can be properly handled by adding a reference to a custom function signature.</P>
		
	<H2>Processor Specification</H2>
	
		<P>A new set of tools designed to make processor specifications easier to create, modify, and validate
		have been added.  The tools consist of a context sensitive Sleigh file editor, a p-code validation
		framework, an external disassembler field, and several scripts to make development easier.
		The Sleigh editor is a plug-in for Eclipse and provides modern editor features such as syntax coloring,
		hover, navigation, code formatting, validation, reference finding, and error
		navigation.  The test suite emulates the p-code to automatically
		validate the instructions most commonly used by the compiler for that processor.</P>
		
	<H2>iOS DYLD and Macho Format</H2>
	
		<P>DYLD shared cache images, extracted from an iOS image, can now be imported in their entirety.
		A DYLD's embedded DYLIB's are split into memory blocks, greatly enhancing follow-on analysis.
		Internal Macho headers are retained and marked up similarly to ELF and PE files, which includes
		tracking the origin of the program bytes from the initial import binary.</P>

	<H2>Ghidra Server</H2>
	    <P>The Ghidra server now requires the client to use a TLS secure connection for the initial RMI registry port access.  
	    Previously, TLS was used for all remote object interactions and data transfers on the two other ports.  This change will 
	    now ensure that all connections to the Ghidra Server utilize TLS.
	    As noted above a 9.1 clients can connect to a 9.0 or 9.1 server, while clients prior to 9.1 will be unable to
	    connect to a 9.1 server.</P>
	    
	    <P>The Ghidra server has two additional authentication methods, Active Directory using
	    Kerberos and Pluggable Authentication Modules (PAM) using JAAS.  To utilize these new
	    methods you must configure the server.conf file and use either -a1 for windows authentication
	    or -a4 along with -jaas.  The JAAS mode will require setup of an additional configuration file (jaas.conf).</P>
	
	<H2>Import</H2>
	    <P>When importing files, the origin of all imported bytes can be tracked back to their offset
	    within the original binary source.  This change lays the ground work for exporting back to the
	    original file after modifying the bytes. There are programmer API methods to get the bytes either
	    from the memory block or the underlying original source bytes.  To see the original bytes a memory
	    block can be mapped onto the original filebytes.  The source of each memory block within the memory
	    map is shown in a new Byte Source column. When hovering on the bytes in the program listing, the
	    origin of the bytes at that address are displayed.</P>
	    
    <H2>Decompiler</H2>
    	<P>The decompiler now implements a more detailed analysis of local variables on the
    	stack.  This change resolves many problems with disappearing
    	structure initialization and incorrect dead code removal. </P>
    	
    	<P>The decompiler now generates fewer duplicate assignments. For example, repeated assignment of
    	the same value to a variable in two branches will now appear
    	before either branch is taken.</P>
    	
    	<P>In addition the decompiler now recognizes more optimization patterns used
    	by compilers for signed division, resulting in simplified decompilation.</P>
    	
    	<P>AARCH64-based binary decompilation will be cleaner due to better handling of
    	zero extensions into larger registers.  This improves data flow analysis and
    	primarily affects functions using floating point Neon instructions.</P>
    	
    	<P>Renaming a parameter in the decompiler will no longer commit the
    	datatypes of all parameters, allowing datatypes
	to continue to "float" without getting locked into a potentially
    	incorrect initial datatype.  In addition, the cumbersome warning dialog
    	for renaming and retyping has been removed, improving your RE workflow.</P>

    <H2>Languages</H2>
    	<P>There are many new processor specifications including SuperH4, MCS-96,
    	HCS12X/XGATE, HCS08, and user-contributed specifications for MCS-48,
    	SuperH1/2a, and Tricore.</P>
    	
    	<P>The 16-bit x86 processor specification has been reworked to include
    	protected mode addressing, which the NE loader now uses by default.  Handling of
    	segmented or paged memory has been updated to use a newer scheme, hiding its
    	complications from decompilation results. The implementation handles the HCS12X paging scheme as well.</P>
    	
    	<P>Many improvements and bug fixes have been made to existing processor
    	specifications: ARM, AARCH64, PIC, 68K, MIPS, PPC, JVM, Sparc, AVR8,
    	8051, 6502, and others.</P>
    	
    	    	
    <H2>Bug Fixes and Enhancements</H2>
    		<P> Numerous other bug fixes and improvements are fully listed in the <a href="ChangeHistory.html">ChangeHistory</a> file.</P>
      
    <BR />
    <H1>What's New in Ghidra 9.0</H1>
    
    	<H2>Ghidra Released to the Public!</H2>
	
		<P>In case you missed it, in March 2019, a public version of Ghidra was released for the first time. Soon after,
		the full buildable source was made available as an open source project on the NSA GitHub page. The response from the Ghidra
		Open Source community has been overwhelmingly positive.  We welcome contributions from GitHub including bug fixes, 
		requests, scripts, processor modules, and plug-ins. </P>
    
    	<H2> Bug Fixes and Enhancements</H2>
    		<P> Bug fixes and improvements for 9.0.x are listed in the
    		<a href="ChangeHistory.html">Change History</a> file.</P>
    		
    <BR>
    
    <P align="center">
    <B><a href="https://www.nsa.gov/ghidra"> https://www.nsa.gov/ghidra</a></B>
    </P>

  </BODY>
</HTML>

